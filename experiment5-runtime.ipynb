{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b20986-6eaf-476f-af70-34d5a6b19fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanhoan310/miniconda3/envs/py310/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 11.0.0. Please consider upgrading.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# py310\n",
    "from model.srnc import SequentialRadiusNeighborsClassifier\n",
    "from model.rejection import classification_rejection_v2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import anndata as ad\n",
    "from anndata import AnnData\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score,adjusted_rand_score,f1_score,precision_score,recall_score\n",
    "# from mars.model.mars import MARS\n",
    "# from mars.experiment_dataset import ExperimentDataset\n",
    "# from args_parser import get_parser\n",
    "\n",
    "# Setting parameters\n",
    "predictive_alg = \"lightGBM\"\n",
    "embedded_option = \"PCA\"\n",
    "shrink_parameter = 1\n",
    "proportion_unknown = 0.2\n",
    "control_neighbor = 5\n",
    "threshold_rejection = 0.8\n",
    "filter_proportion = 5\n",
    "data_name = \"bench\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a37aa2f0-0200-4fde-b844-db187ab95c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data preprocessing\n",
    "# # Note: change the path to dataset\n",
    "# adata_raw = sc.read_h5ad('/data/hoan/project24/SemiSupervisedLearning/Data/bench/cellbench.h5ad')\n",
    "# adata_raw.layers['counts'] = adata_raw.X\n",
    "# adata_raw\n",
    "\n",
    "# label_key = 'ground_truth'\n",
    "# batch_key = 'experiment'\n",
    "# adata = adata_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c70189b-7513-4c39-99d4-96ace54f7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # note that this collection of batches is already intersected on the genes\n",
    "# adata_raw = sc.read(\n",
    "#     \"data/pancreas.h5ad\",\n",
    "#     backup_url=\"https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1\",\n",
    "# )\n",
    "# adata_raw.write('/data/hoan/project24/SemiSupervisedLearning/Data/pancreas.h5ad')\n",
    "adata_raw = sc.read_h5ad('/data/hoan/project24/SemiSupervisedLearning/Data/pancreas.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bdf33bd-9c42-46c9-8b83-6287f870a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_key = 'ground_truth'\n",
    "batch_key = 'experiment'\n",
    "adata = adata_raw.copy()\n",
    "adata.obs[label_key] = adata.obs['celltype']\n",
    "adata.obs[batch_key] = adata.obs['batch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72314fa5-9fa7-48f4-9a18-17ea44406816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14693, 2448)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fe88e1c-8bb0-4428-9581-9ff697ff88f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow is not installed, assuming tensorboard is independent\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "\n",
    "def classification_rejection_v2(X, Y, Y_all_labels, X_train, Y_train,X_test,predictive_alg, threshold_rejection):\n",
    "    if predictive_alg == \"svm\":\n",
    "        clf = svm.SVC(probability=True, max_iter=100000).fit(X_train, Y_train)\n",
    "    if predictive_alg == \"LinearSVM\":\n",
    "        svc = LinearSVC()\n",
    "        clf = CalibratedClassifierCV(svc, cv=sss).fit(X_train, Y_train)\n",
    "        # fix to 5 fold instead of 10 fold ?\n",
    "    if predictive_alg == \"lr\":\n",
    "        clf = LogisticRegression(max_iter=10000).fit(X_train, Y_train)\n",
    "    if predictive_alg == \"lda\":\n",
    "        clf = LinearDiscriminantAnalysis().fit(X_train, Y_train)\n",
    "    if predictive_alg == \"dt\":\n",
    "        clf = DecisionTreeClassifier().fit(X_train, Y_train)\n",
    "    if predictive_alg == \"lightGBM\":\n",
    "        clf = LGBMClassifier(verbose=-1).fit(X_train, Y_train)\n",
    "    if predictive_alg == \"GaussianNB\":\n",
    "        clf = GaussianNB().fit(X_train, Y_train)\n",
    "\n",
    "    probs_max = [np.max(x) for x in clf.predict_proba(X_test)]\n",
    "    Y_predict = list(clf.predict(X_test))\n",
    "    Y_predict_rejection = [Y_predict[i] if probs_max[i] >= threshold_rejection else int(10*len(Y_all_labels) + 1)  for i in range(X_test.shape[0])]\n",
    "    return  Y_predict_rejection\n",
    "\n",
    "from scnym2.api import scnym_api\n",
    "import scanpy as sc\n",
    "import scnym2\n",
    "config = scnym2.api.CONFIGS[\"new_identity_discovery\"]\n",
    "config[\"n_epochs\"] = 10\n",
    "# increase the weight of the domain adversary 0.1 -> 0.3\n",
    "config[\"ssl_kwargs\"][\"dan_max_weight\"] = 0.3\n",
    "config['batch_size'] = 100\n",
    "\n",
    "def run_scNym(annotated, unannotated):\n",
    "    ## scNym\n",
    "    annotated.X = annotated.X-annotated.X.min()+1.0\n",
    "    sc.pp.normalize_total(annotated, target_sum=1e6)  # scale each cell to 1e6 total counts\n",
    "    sc.pp.log1p(annotated)  \n",
    "    scnym_api(\n",
    "        adata=annotated,\n",
    "        task='train',\n",
    "        groupby='ground_truth',\n",
    "        out_path='scnym_output',\n",
    "        config=config\n",
    "    )\n",
    "    unannotated.X = unannotated.X-unannotated.X.min()+1\n",
    "    sc.pp.normalize_total(unannotated, target_sum=1e6)  # scale each cell to 1e6 total counts\n",
    "    sc.pp.log1p(unannotated)  \n",
    "    scnym_api(\n",
    "        adata=unannotated,\n",
    "        task='predict',\n",
    "        key_added='scNym',\n",
    "        trained_model='scnym_output',\n",
    "        out_path='scnym_output',\n",
    "        config=config,\n",
    "    )\n",
    "    Y_predict_rejection = list(unannotated.obs['scNym'])\n",
    "    return Y_predict_rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c67075c-414e-4234-9829-b440a3961072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch-aware feature selection\n",
    "sc.pp.highly_variable_genes(adata,n_top_genes=2000, flavor=\"cell_ranger\", batch_key=batch_key)\n",
    "\n",
    "# use selected genes for integration\n",
    "adata_hvg = adata[:,adata.var[\"highly_variable\"]].copy()\n",
    "\n",
    "# run pca\n",
    "sc.pp.pca(adata_hvg, n_comps=50)\n",
    "adata_hvg.obsm[\"X_pca\"] = adata_hvg.obsm[\"X_pca\"]\n",
    "\n",
    "# run combat integration to correct for sample and condition effects\n",
    "sc.pp.combat(adata_hvg, key=batch_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42adca81-3fa2-4387-90f5-17fd58419ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 14693 × 2000\n",
       "    obs: 'celltype', 'sample', 'n_genes', 'batch', 'n_counts', 'louvain', 'ground_truth', 'experiment'\n",
       "    var: 'n_cells-0', 'n_cells-1', 'n_cells-2', 'n_cells-3', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'\n",
       "    uns: 'celltype_colors', 'louvain', 'neighbors', 'pca', 'sample_colors', 'hvg'\n",
       "    obsm: 'X_pca', 'X_umap'\n",
       "    varm: 'PCs'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_hvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3d7af24-24c6-4e47-a012-6c31588a37de",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_hvg.obs['ground_truth'] = adata_hvg.obs['ground_truth'].astype('category')\n",
    "adata_hvg.obs['ground_truth'] = adata_hvg.obs['ground_truth'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce39e75d-1c19-4fc9-bfb2-32565165da43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data experiment...\n",
      "Class removed from training:5\n",
      "(784, 50) (1000, 50)\n",
      "Done\n",
      "[0.2671634554862976]\n",
      "Data experiment...\n",
      "Class removed from training:4\n",
      "(1384, 50) (2000, 50)\n",
      "Done\n",
      "[0.2671634554862976, 0.3791256586710612]\n",
      "Data experiment...\n",
      "Class removed from training:18\n",
      "(4942, 50) (5000, 50)\n",
      "Done\n",
      "[0.2671634554862976, 0.3791256586710612, 0.7298123160998027]\n",
      "Data experiment...\n",
      "Class removed from training:12\n",
      "(9599, 50) (10000, 50)\n",
      "Done\n",
      "[0.2671634554862976, 0.3791256586710612, 0.7298123160998027, 1.5031184911727906]\n",
      "Data experiment...\n",
      "Class removed from training:5\n",
      "(11339, 50) (14693, 50)\n",
      "Done\n",
      "[0.2671634554862976, 0.3791256586710612, 0.7298123160998027, 1.5031184911727906, 2.808844629923503]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "runtime_vec = []\n",
    "n_total = adata.n_obs\n",
    "predictive_alg = 'lightGBM'\n",
    "# Sample data\n",
    "for n_subsample in [1000, 2000, 5000, 10000, n_total]:\n",
    "    start = time.time()\n",
    "    idx_train = np.random.choice(n_total, n_subsample, replace=False)\n",
    "    idx_test = np.random.choice(n_total, n_subsample, replace=False)\n",
    "    \n",
    "    # Subsample the AnnData\n",
    "    # adata_sub = adata[idx, :].copy()\n",
    "    \n",
    "    exp_10x = adata_hvg[idx_train, :].copy()\n",
    "    # X_exp_10x = exp_10x.X\n",
    "    X_exp_10x = exp_10x.obsm[\"X_pca\"]\n",
    "    y_exp_10x = np.array(exp_10x.obs['ground_truth'], dtype=np.int64)\n",
    "    \n",
    "    exp_celseq2 = adata_hvg[idx_test, :].copy()\n",
    "    # X_celseq2 = exp_celseq2.X\n",
    "    X_celseq2 = exp_celseq2.obsm[\"X_pca\"]\n",
    "    y_celseq2 = np.array(exp_celseq2.obs['ground_truth'], dtype=np.int64)\n",
    "    \n",
    "    # Loop to remove label randomly\n",
    "    # for i in np.unique(y_exp_10x):\n",
    "    remove_label = y_exp_10x[0]\n",
    "    X_10x = X_exp_10x[y_exp_10x != remove_label]\n",
    "    y_10x = y_exp_10x[y_exp_10x != remove_label]\n",
    "    \n",
    "    print(\"Data experiment...\")\n",
    "    print(f\"Class removed from training:{remove_label}\")\n",
    "    \n",
    "    \n",
    "    # annotated_data = ExperimentDataset(X_10x.toarray(), exp_10x.obs_names, exp_10x.var_names, '10x', y_10x)\n",
    "    # unannotated_data = ExperimentDataset(X_celseq2.toarray(), exp_celseq2.obs_names, exp_celseq2.var_names, 'celseq2', y_celseq2)\n",
    "    # pretrain_data = ExperimentDataset(X_celseq2.toarray(), exp_celseq2.obs_names, exp_celseq2.var_names, 'celseq2')\n",
    "    # n_clusters = len(np.unique(unannotated_data.y))\n",
    "    \n",
    "    # Create AnnData object and add value from dataframe\n",
    "    \n",
    "    annotated = ad.AnnData(X=X_10x)\n",
    "    annotated.obs['ground_truth'] = y_10x\n",
    "    annotated.obs['experiment'] = '10x'\n",
    "    \n",
    "    unannotated = ad.AnnData(X=X_celseq2)\n",
    "    unannotated.obs['ground_truth'] = y_celseq2\n",
    "    unannotated.obs['experiment'] = 'celseq2'\n",
    "    \n",
    "    annotated.obs_names = [f\"Cell_{i:d}\" for i in range(annotated.n_obs)]\n",
    "    annotated.var_names = [f\"Gene_{i:d}\" for i in range(annotated.n_vars)]\n",
    "    \n",
    "    unannotated.obs_names = [f\"Cell_{i:d}\" for i in range(unannotated.n_obs)]\n",
    "    unannotated.var_names = [f\"Gene_{i:d}\" for i in range(unannotated.n_vars)]\n",
    "    \n",
    "    annotated_y = np.array(annotated.obs['ground_truth'], dtype=np.int64)\n",
    "    annotated_x = np.asarray(annotated.X)\n",
    "    \n",
    "    # #  MARS implementation\n",
    "    # annotated_set = ExperimentDataset(annotated_x, annotated.obs_names, annotated.var_names, data_name, annotated_y)\n",
    "    \n",
    "    unannotated_y = np.array(unannotated.obs['ground_truth'], dtype=np.int64)\n",
    "    unannotated_x = np.asarray(unannotated.X)\n",
    "    \n",
    "    # unannotated_set = ExperimentDataset(unannotated_x, unannotated.obs_names, unannotated.var_names, data_name, unannotated_y)\n",
    "    \n",
    "    \n",
    "    # pretrain_data = ExperimentDataset(unannotated_x, unannotated.obs_names, unannotated.var_names, data_name)\n",
    "    \n",
    "    # n_clusters=len(np.unique(unannotated_data.y))\n",
    "    # print(n_clusters)\n",
    "    # mars = MARS(n_clusters, params, [annotated_set], unannotated_set, pretrain_data, hid_dim_1=1000, hid_dim_2=100)\n",
    "    # adata, landmarks, scores = mars.train(evaluation_mode=True, save_all_embeddings=False)\n",
    "    # print(adata)\n",
    "    # scores\n",
    "    \n",
    "    \n",
    "    # SRNC and Rejection implementation\n",
    "    data_embbed_x = np.concatenate([annotated_x,unannotated_x])\n",
    "    data_embbed_y = np.concatenate([annotated_y,unannotated_y])\n",
    "    y_all_labels = list(set(data_embbed_y))\n",
    "    \n",
    "    \n",
    "    Y_predict_srnc=SequentialRadiusNeighborsClassifier(data_embbed_x, y_all_labels, annotated_x, unannotated_x, annotated_y, predictive_alg,\n",
    "                                            control_neighbor, shrink_parameter, filter_proportion, threshold_rejection)\n",
    "    \n",
    "    \n",
    "    # Y_predict_rejection=classification_rejection_v2(data_embbed_x,data_embbed_y,y_all_labels,annotated_x,annotated_y,unannotated_x,predictive_alg,threshold_rejection)\n",
    "    # predictive_alg = 'scNym'\n",
    "    # Y_predict_rejection=run_scNym(annotated, unannotated)\n",
    "    print(annotated_x.shape, unannotated_x.shape)\n",
    "    print('Done')\n",
    "    end = time.time()\n",
    "    runtime_vec.append((end-start)/60.0)\n",
    "    print(runtime_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82bf7c7a-cc5d-4d45-b762-d41a0ba1bea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2671634554862976,\n",
       " 0.3791256586710612,\n",
       " 0.7298123160998027,\n",
       " 1.5031184911727906,\n",
       " 2.808844629923503]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711bff4f-489a-41c9-a63b-2c1156819d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
